{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ca1dfec",
   "metadata": {},
   "source": [
    "# Text classification with a Bag-of-Words approach: a case study for sentiment analysis\n",
    "\n",
    "Classifying texts is the task of assigning a label to each of the elements of a dataset. In text classification, this task is achieved by analyzing and extracting information from text data. One patent example of such is the task of sentiment analysis.\n",
    "\n",
    "Sentiment analysis is the task of identifying if the general sentiment of an excerpt should be considered \"positive\" or \"negative\". Although this is a well known and largely studied problem, it has gained a special importance in the last few years because of the need to monitor social media to find floating sentiments towards particular entities."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dda495cd",
   "metadata": {},
   "source": [
    "## Classification by logistic regression\n",
    "\n",
    "One of the ways to perform classification is using Logistic Regression (LR). LR can be seen as a classification counterpart of linear regression. In linear regression, a vector $x$ of continuous features is multiplied by the transpose $w^T$ of a weight vector and has some bias added, yieding:\n",
    "\n",
    "$$\n",
    "z = xw^t + b.\n",
    "$$\n",
    "\n",
    "Note that this is equivalent to stating that $z = b+ \\sum_{i=1}^n x_nw_n$, that is, there is one element in $w$ for each element in $x$ and this element represents the weight given to that element in the final sum.\n",
    "\n",
    "Logistic Regression solves the problem of identifying the class (\"positive\" or \"negative\") that $x$ belongs to. In LR, the final output $y$ is given by $\\sigma(z)$, where:\n",
    "\n",
    "$$\n",
    "y=\\sigma(z)=\\frac{1}{1+e^{-z}}.\n",
    "$$\n",
    "\n",
    "This allows interpreting $y$ as the probability that $x$ belongs to the \"positive\" class. Consequently, the weights $w$ and the bias $b$ can be optimized by minimizing the cross entropy loss regarding a labeled dataset.\n",
    "\n",
    "Importantly, Logistic Regression calls for representing each element in the dataset using a vector. One of the solutions for such is the Bag-of-Words approach."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fce5d5d",
   "metadata": {},
   "source": [
    "## Representing texts using Bag-of-words\n",
    "\n",
    "The \"bag\" in bag of words brings the idea that all words from a text are put into a bag and then shuffled. In this case, each element from a text dataset is represented by a vector $x \\in \\mathbb{R}^V$, where $V$ is the number of words in the vocabulary. Thus, $x_i$ corresponds to the $i$-th word in the vocabulary.\n",
    "\n",
    "The simplest way to find $x$ is to assume $x_i$ is $1$ if the corresponding word exists in the text, and $0$ if it does not, which makes each word follow a Bernoulli distribution. Another method is to make $x_i$ equal to the number of times the corresponding word appears in the text. This word count is called \"Term Frequency\" (TF).\n",
    "\n",
    "Another method it to divide TF by the number of documents the corresponding words appears in (that is, the Document Frequency DF). This method is called Term Frequency - Inverse Document Frequency (TFIDF), and yields a vector that informs how much each word is relevant to separate that document from the whole collection.\n",
    "\n",
    "Using BoW and LR is straightforward in Scikit Learn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "30a528f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Create a pipeline with TfidfVectorizer and LogisticRegression\n",
    "pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('clf', LogisticRegression())\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85349dd4",
   "metadata": {},
   "source": [
    "## Dataset: IMDB dataset\n",
    "\n",
    "In this study, we use the IMDB dataset because it is a well-known dataset. It is comprised of movie reviews extracted from the IMDB website. Reviews associated with a star rating of 4 our five are considered positive, whereas reviews associate with a star rating of 1 or 2 are considered negative. Reviews with a star rating of 3 are excluded form the dataset. The dataset is pre-divided into train and test sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d6b86e4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.7), please consider upgrading to the latest version (0.3.12).\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "from pathlib import Path\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"columbine/imdb-dataset-sentiment-analysis-in-csv-format\")\n",
    "path = Path(path)\n",
    "#print(\"Path to dataset files:\", path)\n",
    "#print(\"Directory contents:\", list(path.iterdir()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7dd231c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "text",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "label",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "d088f320-d31d-4953-a264-aa5e5e97ccb3",
       "rows": [
        [
         "0",
         "I grew up (b. 1965) watching and loving the Thunderbirds. All my mates at school watched. We played \"Thunderbirds\" before school, during lunch and after school. We all wanted to be Virgil or Scott. No one wanted to be Alan. Counting down from 5 became an art form. I took my children to see the movie hoping they would get a glimpse of what I loved as a child. How bitterly disappointing. The only high point was the snappy theme tune. Not that it could compare with the original score of the Thunderbirds. Thankfully early Saturday mornings one television channel still plays reruns of the series Gerry Anderson and his wife created. Jonatha Frakes should hand in his directors chair, his version was completely hopeless. A waste of film. Utter rubbish. A CGI remake may be acceptable but replacing marionettes with Homo sapiens subsp. sapiens was a huge error of judgment.",
         "0"
        ],
        [
         "1",
         "When I put this movie in my DVD player, and sat down with a coke and some chips, I had some expectations. I was hoping that this movie would contain some of the strong-points of the first movie: Awsome animation, good flowing story, excellent voice cast, funny comedy and a kick-ass soundtrack. But, to my disappointment, not any of this is to be found in Atlantis: Milo's Return. Had I read some reviews first, I might not have been so let down. The following paragraph will be directed to those who have seen the first movie, and who enjoyed it primarily for the points mentioned.<br /><br />When the first scene appears, your in for a shock if you just picked Atlantis: Milo's Return from the display-case at your local videoshop (or whatever), and had the expectations I had. The music feels as a bad imitation of the first movie, and the voice cast has been replaced by a not so fitting one. (With the exception of a few characters, like the voice of Sweet). The actual drawings isnt that bad, but the animation in particular is a sad sight. The storyline is also pretty weak, as its more like three episodes of Schooby-Doo than the single adventurous story we got the last time. But dont misunderstand, it's not very good Schooby-Doo episodes. I didnt laugh a single time, although I might have sniggered once or twice.<br /><br />To the audience who haven't seen the first movie, or don't especially care for a similar sequel, here is a fast review of this movie as a stand-alone product: If you liked schooby-doo, you might like this movie. If you didn't, you could still enjoy this movie if you have nothing else to do. And I suspect it might be a good kids movie, but I wouldn't know. It might have been better if Milo's Return had been a three-episode series on a cartoon channel, or on breakfast TV.",
         "0"
        ],
        [
         "2",
         "Why do people who do not know what a particular time in the past was like feel the need to try to define that time for others? Replace Woodstock with the Civil War and the Apollo moon-landing with the Titanic sinking and you've got as realistic a flick as this formulaic soap opera populated entirely by low-life trash. Is this what kids who were too young to be allowed to go to Woodstock and who failed grade school composition do? \"I'll show those old meanies, I'll put out my own movie and prove that you don't have to know nuttin about your topic to still make money!\" Yeah, we already know that. The one thing watching this film did for me was to give me a little insight into underclass thinking. The next time I see a slut in a bar who looks like Diane Lane, I'm running the other way. It's child abuse to let parents that worthless raise kids. It's audience abuse to simply stick Woodstock and the moonlanding into a flick as if that ipso facto means the film portrays 1969.",
         "0"
        ],
        [
         "3",
         "Even though I have great interest in Biblical movies, I was bored to death every minute of the movie. Everything is bad. The movie is too long, the acting is most of the time a Joke and the script is horrible. I did not get the point in mixing the story about Abraham and Noah together. So if you value your time and sanity stay away from this horror.",
         "0"
        ],
        [
         "4",
         "Im a die hard Dads Army fan and nothing will ever change that. I got all the tapes, DVD's and audiobooks and every time i watch/listen to them its brand new. <br /><br />The film. The film is a re run of certain episodes, Man and the hour, Enemy within the gates, Battle School and numerous others with a different edge. Introduction of a new General instead of Captain Square was a brilliant move - especially when he wouldn't cash the cheque (something that is rarely done now).<br /><br />It follows through the early years of getting equipment and uniforms, starting up and training. All in all, its a great film for a boring Sunday afternoon. <br /><br />Two draw backs. One is the Germans bogus dodgy accents (come one, Germans cant pronounced the letter \"W\" like us) and Two The casting of Liz Frazer instead of the familiar Janet Davis. I like Liz in other films like the carry ons but she doesn't carry it correctly in this and Janet Davis would have been the better choice.",
         "1"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I grew up (b. 1965) watching and loving the Th...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>When I put this movie in my DVD player, and sa...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Why do people who do not know what a particula...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Even though I have great interest in Biblical ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Im a die hard Dads Army fan and nothing will e...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  I grew up (b. 1965) watching and loving the Th...      0\n",
       "1  When I put this movie in my DVD player, and sa...      0\n",
       "2  Why do people who do not know what a particula...      0\n",
       "3  Even though I have great interest in Biblical ...      0\n",
       "4  Im a die hard Dads Army fan and nothing will e...      1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "test_df = pd.read_csv(path / \"Test.csv\")\n",
    "train_df = pd.read_csv(path / \"Train.csv\")\n",
    "train_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "21a711b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.89      0.90      2495\n",
      "           1       0.89      0.91      0.90      2505\n",
      "\n",
      "    accuracy                           0.90      5000\n",
      "   macro avg       0.90      0.90      0.90      5000\n",
      "weighted avg       0.90      0.90      0.90      5000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "pipeline.fit(train_df['text'], train_df['label'])\n",
    "y_pred = pipeline.predict(test_df['text'])\n",
    "report = classification_report(test_df['label'], y_pred)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dfc0ab0",
   "metadata": {},
   "source": [
    "As we can see, the results are reasonable. Hence, we can proceed to analyze the model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5389ae95",
   "metadata": {},
   "source": [
    "## Why did it classify as it did?\n",
    "\n",
    "We can identify which words are typically the most important for classification. For such, we sweep the whole vocabulary and find $y$ corresponding to each of the inputs. The words with largest $y$ are associated with the \"positive\" class, whereas the words with lower $y$ are associated with the \"negative\" class. We can use `predict_proba` to find the values of $y$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a89e95f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Extract the vocabulary and the classifier from the pipeline\n",
    "vocab = pipeline.named_steps['tfidf'].vocabulary_\n",
    "clf = pipeline.named_steps['clf']\n",
    "\n",
    "# Get the feature names (words) from the TfidfVectorizer\n",
    "feature_names = np.array(pipeline.named_steps['tfidf'].get_feature_names_out())\n",
    "# Calculate predict_proba for each word\n",
    "probabilities = pipeline.predict_proba(feature_names)\n",
    "\n",
    "# Create a dataframe with words and their probabilities\n",
    "proba_df = pd.DataFrame(probabilities, index=feature_names, columns=clf.classes_)\n",
    "proba_df.rename(columns={1 : 'positive', 0 : 'negative'}, inplace=True)\n",
    "proba_df = proba_df.sort_values(by='positive', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b1c0a841",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "negative",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "positive",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "ab2a643c-00d3-4c2d-bb29-2bd9c2440af0",
       "rows": [
        [
         "great",
         "0.0001628011121629358",
         "0.9998371988878371"
        ],
        [
         "excellent",
         "0.0007781155227236658",
         "0.9992218844772763"
        ],
        [
         "best",
         "0.0032819569117085168",
         "0.9967180430882915"
        ],
        [
         "wonderful",
         "0.004254044351163944",
         "0.9957459556488361"
        ],
        [
         "amazing",
         "0.005403281091213796",
         "0.9945967189087862"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>negative</th>\n",
       "      <th>positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>great</th>\n",
       "      <td>0.000163</td>\n",
       "      <td>0.999837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>excellent</th>\n",
       "      <td>0.000778</td>\n",
       "      <td>0.999222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>best</th>\n",
       "      <td>0.003282</td>\n",
       "      <td>0.996718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wonderful</th>\n",
       "      <td>0.004254</td>\n",
       "      <td>0.995746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>amazing</th>\n",
       "      <td>0.005403</td>\n",
       "      <td>0.994597</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           negative  positive\n",
       "great      0.000163  0.999837\n",
       "excellent  0.000778  0.999222\n",
       "best       0.003282  0.996718\n",
       "wonderful  0.004254  0.995746\n",
       "amazing    0.005403  0.994597"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proba_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4f24fd3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "negative",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "positive",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "dfe4967e-13f8-482f-a718-c8d70c6d127c",
       "rows": [
        [
         "boring",
         "0.9992887865502033",
         "0.0007112134497967962"
        ],
        [
         "awful",
         "0.9997019336164269",
         "0.000298066383573057"
        ],
        [
         "waste",
         "0.99971130196021",
         "0.0002886980397900467"
        ],
        [
         "bad",
         "0.9998968258524626",
         "0.00010317414753735826"
        ],
        [
         "worst",
         "0.9999874192457195",
         "1.258075428045885e-05"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>negative</th>\n",
       "      <th>positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>boring</th>\n",
       "      <td>0.999289</td>\n",
       "      <td>0.000711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>awful</th>\n",
       "      <td>0.999702</td>\n",
       "      <td>0.000298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>waste</th>\n",
       "      <td>0.999711</td>\n",
       "      <td>0.000289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bad</th>\n",
       "      <td>0.999897</td>\n",
       "      <td>0.000103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>worst</th>\n",
       "      <td>0.999987</td>\n",
       "      <td>0.000013</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        negative  positive\n",
       "boring  0.999289  0.000711\n",
       "awful   0.999702  0.000298\n",
       "waste   0.999711  0.000289\n",
       "bad     0.999897  0.000103\n",
       "worst   0.999987  0.000013"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proba_df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaa39b97",
   "metadata": {},
   "source": [
    "As we can see, positive adjectives are associated with the positive class, while negative adjectives are associated with the negative class. This means that our system uses words that are meaningful towards our purpose. This can be seen as evidence that our model is not classifying based on spurious elements."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48e812d5",
   "metadata": {},
   "source": [
    "## How much data do we need?\n",
    "\n",
    "It is common to see phrases such as \"the more data, the better\". However, this is only true to some extent. To find the possible impact of enlarging our dataset, we commonly use a Learning Curve. A Learning Curve is a curve made by changing the size of the training set and then evaluating the accuracy for each training dataset size.\n",
    "\n",
    "The expected behavior is that the accuracy in the test set increases, while the accuracy in the train set decreases, until they asymptotically meet. This \"meeting point\" indicates the maximum amount of data that can lead to better results with the evaluated model, as well as the maximum accuracy for that same model. We can calculate the learning curve as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b57b9f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import learning_curve\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Generate learning curve data\n",
    "train_sizes, train_scores, test_scores = learning_curve(\n",
    "    pipeline, train_df['text'], train_df['label'], cv=5, scoring='accuracy', n_jobs=-1, train_sizes=np.logspace(-2, 0, 10)\n",
    ")\n",
    "\n",
    "# Calculate mean and standard deviation for training and test scores\n",
    "train_scores_mean = np.mean(train_scores, axis=1)\n",
    "train_scores_std = np.std(train_scores, axis=1)\n",
    "test_scores_mean = np.mean(test_scores, axis=1)\n",
    "test_scores_std = np.std(test_scores, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2a73b90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the learning curve\n",
    "plt.figure(figsize=(5, 3))\n",
    "plt.plot(train_sizes, train_scores_mean, label='Training score', color='blue')\n",
    "plt.fill_between(train_sizes, train_scores_mean - 2*train_scores_std, train_scores_mean + 2*train_scores_std, color='blue', alpha=0.2)\n",
    "plt.plot(train_sizes, test_scores_mean, label='Cross-validation score', color='orange')\n",
    "plt.fill_between(train_sizes, test_scores_mean - 2*test_scores_std, test_scores_mean + 2*test_scores_std, color='orange', alpha=0.2)\n",
    "\n",
    "plt.title('Learning Curve')plt.xlabel('Training Set Size')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(loc='best')\n",
    "plt.semilogx()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f3ff792",
   "metadata": {},
   "source": [
    "As we can see, if we had around $10^5$ data points (that is, a dataset at least twice as large as ours), our accuracy would probably reach around 92% accuracy. This means that adding more data would present diminishing gains."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62f0df96",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In this case study, we used a TFIDF+LR pipeline to classify sentiments in the IMDB dataset. As we can see, the words used for classification are meaningful towards writing positive or negative reviews, which indicates the model is well-fitting. Also, the accuracy in the train and test sets is relatively low, which indicates the dataset size is adequate for this problem.\n",
    "\n",
    "Importantly, although the BoW model disregards the order in which words appear, it is able to capture the fact that some words are more likely to be used in particular contexts. Henceforth, this apparent disadvantage is not necessarily harmful to any classification problem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a524659",
   "metadata": {},
   "source": [
    "# Activities\n",
    "\n",
    "## Questions\n",
    "\n",
    "**Remembering (Recall facts and basic concepts)**\n",
    "\n",
    "1.  What is the main task being performed in this case study?\n",
    "2.  What machine learning algorithm is used for the classification task?\n",
    "3.  What technique is used to convert the text reviews into numerical feature vectors?\n",
    "4.  What specific variant of Bag-of-Words is used in the Scikit-learn pipeline? (TF-IDF)\n",
    "5.  What dataset is used for training and testing the model?\n",
    "6.  How were the labels (positive/negative) determined for the reviews in the IMDB dataset?\n",
    "\n",
    "**Understanding (Explain ideas or concepts)**\n",
    "\n",
    "7.  Explain in your own words the core idea behind the Bag-of-Words (BoW) text representation.\n",
    "8.  What is the purpose of the TF-IDF (Term Frequency-Inverse Document Frequency) weighting scheme compared to just counting word occurrences (Term Frequency)?\n",
    "9.  Why is a Scikit-learn `Pipeline` useful for combining the vectorization and classification steps?\n",
    "10. What does the learning curve plotted in the notebook illustrate? What do the two lines (training score and cross-validation score) represent?\n",
    "11. Explain the rationale behind analyzing the `predict_proba` scores for individual words in the vocabulary. What was the author trying to determine?\n",
    "\n",
    "**Applying (Use information in new situations)**\n",
    "\n",
    "12. How would you modify the code cell defining the `pipeline` to use a simple count vectorizer (Term Frequency) instead of TF-IDF?\n",
    "13. If you were given a new, unseen movie review text, what line(s) of code would you use (after the pipeline is trained) to predict whether it's positive or negative?\n",
    "14. Based on the learning curve shown, if you doubled the training data again (to approx. 200,000 reviews), what would you *roughly* expect to happen to the cross-validation accuracy?\n",
    "\n",
    "**Analyzing (Draw connections among ideas, compare/contrast, break down)**\n",
    "\n",
    "15. Analyze the classification report. What does it tell you about the model's ability to correctly identify positive reviews versus negative reviews? Are there significant differences in precision or recall?\n",
    "16. Compare the TF-IDF approach used here with a hypothetical approach that only uses word presence/absence (Bernoulli). What kind of information does TF-IDF capture that the simpler method doesn't?\n",
    "17. What potential limitation of the Bag-of-Words approach is mentioned in the notebook's conclusion? Why might this limitation not be completely detrimental for this specific sentiment analysis task?\n",
    "18. Looking at the learning curve, are the training and cross-validation scores close together or far apart as the training set size increases? What does this gap (or lack thereof) suggest about model variance or bias?\n",
    "\n",
    "**Evaluating (Justify a stand or decision, critique)**\n",
    "\n",
    "19. Evaluate the author's statement: \"the dataset size is adequate for this problem.\" Do you agree or disagree based *only* on the evidence presented in the learning curve? Justify your position.\n",
    "20. Critique the interpretability analysis performed (predicting probability for single words). While insightful, what potential inaccuracies or simplifications does this method introduce compared to how words contribute within a full review?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41cb32a6",
   "metadata": {},
   "source": [
    "## Suggested answers\n",
    "\n",
    "**Remembering**\n",
    "\n",
    "1.  **What is the main task being performed in this case study?**\n",
    "    *   Suggested Answer: The main task is sentiment analysis, which is a type of text classification aimed at identifying whether a piece of text expresses a positive or negative sentiment.\n",
    "\n",
    "2.  **What machine learning algorithm is used for the classification task?**\n",
    "    *   Suggested Answer: Logistic Regression (LR) is used for the classification task.\n",
    "\n",
    "3.  **What technique is used to convert the text reviews into numerical feature vectors?**\n",
    "    *   Suggested Answer: The Bag-of-Words (BoW) approach is used to convert text into numerical vectors.\n",
    "\n",
    "4.  **What specific variant of Bag-of-Words is used in the Scikit-learn pipeline? (TF-IDF)**\n",
    "    *   Suggested Answer: The specific variant used is Term Frequency-Inverse Document Frequency (TF-IDF), implemented via `TfidfVectorizer`.\n",
    "\n",
    "5.  **What dataset is used for training and testing the model?**\n",
    "    *   Suggested Answer: The IMDB movie review dataset is used.\n",
    "\n",
    "6.  **How were the labels (positive/negative) determined for the reviews in the IMDB dataset?**\n",
    "    *   Suggested Answer: Reviews with a star rating of 4 or 5 were considered positive (label 1), and reviews with a rating of 1 or 2 were considered negative (label 0). Reviews with a 3-star rating were excluded.\n",
    "\n",
    "**Understanding**\n",
    "\n",
    "7.  **Explain in your own words the core idea behind the Bag-of-Words (BoW) text representation.**\n",
    "    *   Suggested Answer: BoW treats a text document as an unordered collection (like words thrown into a bag) of its words, disregarding grammar and word order. It represents the document as a numerical vector where each dimension corresponds to a unique word in the entire dataset's vocabulary, and the value in that dimension indicates the presence, count, or weighted frequency (like TF-IDF) of that word in the document.\n",
    "\n",
    "8.  **What is the purpose of the TF-IDF (Term Frequency-Inverse Document Frequency) weighting scheme compared to just counting word occurrences (Term Frequency)?**\n",
    "    *   Suggested Answer: TF-IDF aims to give higher importance to words that are frequent in a specific document but rare across the entire collection of documents. It down-weights words that appear very commonly everywhere (like \"the\", \"a\", \"is\"), which are less informative for distinguishing between documents, and boosts the weight of terms that are more unique or characteristic of a particular document.\n",
    "\n",
    "9.  **Why is a Scikit-learn `Pipeline` useful for combining the vectorization and classification steps?**\n",
    "    *   Suggested Answer: A `Pipeline` is useful because it chains the text vectorization (TF-IDF) and classification (Logistic Regression) steps into a single object. This simplifies the process of training and prediction, ensuring that the same transformations are applied consistently to both training and testing data. It also helps prevent data leakage, as the vectorizer is fitted only on the training data within the cross-validation folds when used with functions like `learning_curve`.\n",
    "\n",
    "10. **What does the learning curve plotted in the notebook illustrate? What do the two lines (training score and cross-validation score) represent?**\n",
    "    *   Suggested Answer: The learning curve illustrates how the model's performance (accuracy) changes as the amount of training data increases. The 'Training score' line shows the model's accuracy on the data it was trained on at each size point. The 'Cross-validation score' line shows the model's average accuracy on unseen data (validation sets from cross-validation) at each training size point, giving a better estimate of how well the model generalizes.\n",
    "\n",
    "11. **Explain the rationale behind analyzing the `predict_proba` scores for individual words in the vocabulary. What was the author trying to determine?**\n",
    "    *   Suggested Answer: The rationale was to interpret the model and understand *which* words it learned to associate most strongly with positive and negative sentiments. By feeding individual words (as documents) into the trained pipeline and getting their predicted probabilities, the author could identify the words that the model considered the strongest indicators of positivity (high probability for class 1) and negativity (high probability for class 0), providing evidence for whether the model learned meaningful features.\n",
    "\n",
    "**Applying**\n",
    "\n",
    "12. **How would you modify the code cell defining the `pipeline` to use a simple count vectorizer (Term Frequency) instead of TF-IDF?**\n",
    "    *   Suggested Answer: You would import `CountVectorizer` from `sklearn.feature_extraction.text` and replace `TfidfVectorizer()` with `CountVectorizer()` in the pipeline definition:\n",
    "        ```python\n",
    "        from sklearn.feature_extraction.text import CountVectorizer\n",
    "        pipeline = Pipeline([\n",
    "            ('cv', CountVectorizer()), # Changed from 'tfidf', TfidfVectorizer()\n",
    "            ('clf', LogisticRegression())\n",
    "        ])\n",
    "        ```\n",
    "\n",
    "13. **If you were given a new, unseen movie review text, what line(s) of code would you use (after the pipeline is trained) to predict whether it's positive or negative?**\n",
    "    *   Suggested Answer: Assuming the trained pipeline object is named `pipeline` and the new review text is stored in a variable `new_review`, you would use:\n",
    "        ```python\n",
    "        prediction = pipeline.predict([new_review])\n",
    "        ```\n",
    "\n",
    "14. **Based on the learning curve shown, if you doubled the training data again (to approx. 200,000 reviews), what would you *roughly* expect to happen to the cross-validation accuracy?**\n",
    "    *   Suggested Answer: The learning curve shows the cross-validation score is starting to plateau around 40,000 samples (the end of the x-axis). Doubling the data again would likely lead to only very small, diminishing gains in accuracy, possibly increasing slightly towards the projected ~92%, but the improvement would be much less significant than the gains seen with smaller dataset sizes.\n",
    "\n",
    "**Analyzing**\n",
    "\n",
    "15. **Analyze the classification report. What does it tell you about the model's ability to correctly identify positive reviews versus negative reviews? Are there significant differences in precision or recall?**\n",
    "    *   Suggested Answer: The classification report shows that the model performs very similarly well on both positive (1) and negative (0) classes. The precision, recall, and F1-scores are all around 0.90 for both classes. There are no significant differences, indicating the model is balanced in its ability to identify both positive and negative reviews correctly.\n",
    "\n",
    "16. **Compare the TF-IDF approach used here with a hypothetical approach that only uses word presence/absence (Bernoulli). What kind of information does TF-IDF capture that the simpler method doesn't?**\n",
    "    *   Suggested Answer: TF-IDF captures two key pieces of information that a simple Bernoulli (presence/absence) approach doesn't: 1) **Term Frequency:** How often a word appears within a single document (a word appearing multiple times might be more important than one appearing once). 2) **Inverse Document Frequency:** How common or rare a word is across all documents (rare words are often more discriminative). By combining these, TF-IDF provides a weighted score reflecting a word's importance, whereas Bernoulli only provides a binary indication of presence.\n",
    "\n",
    "17. **What potential limitation of the Bag-of-Words approach is mentioned in the notebook's conclusion? Why might this limitation not be completely detrimental for this specific sentiment analysis task?**\n",
    "    *   Suggested Answer: The limitation mentioned is that BoW disregards the order in which words appear, losing sequence and grammatical structure information. This might not be completely detrimental for sentiment analysis because the overall sentiment is often strongly conveyed by the presence of specific sentiment-bearing keywords (like \"amazing,\" \"awful,\" \"boring,\" \"great\") regardless of their exact position or the sentence structure. The model can still learn that certain words are highly correlated with positive or negative labels.\n",
    "\n",
    "18. **Looking at the learning curve, are the training and cross-validation scores close together or far apart as the training set size increases? What does this gap (or lack thereof) suggest about model variance or bias?**\n",
    "    *   Suggested Answer: As the training set size increases, the training and cross-validation scores get closer together (converge). A small gap suggests low variance, meaning the model is not overfitting significantly to the training data and generalizes relatively well. If both scores converge at a level below desired performance, it could indicate higher bias (the model might be too simple to capture all the nuances). In this case, they converge around 90%, which is quite good, suggesting a reasonable balance, though the slight remaining gap and upward trend hint there's still a tiny bit of variance or potential for improvement with more data/model complexity.\n",
    "\n",
    "**Evaluating**\n",
    "\n",
    "19. **Evaluate the author's statement: \"the dataset size is adequate for this problem.\" Do you agree or disagree based *only* on the evidence presented in the learning curve? Justify your position.**\n",
    "    *   Suggested Answer: Based purely on the learning curve, the statement is reasonable but perhaps slightly optimistic regarding maximizing performance. The curve shows good performance (~90% accuracy) is achieved with the current data, and the cross-validation score is flattening, indicating diminishing returns from more data. So, it's adequate for achieving *good* results. However, the curve hasn't *completely* flattened, suggesting that more data (as the author estimates up to ~100k) *could* still provide a small improvement (potentially reaching ~92%). Therefore, while adequate for practical purposes and achieving high accuracy, it might not be fully adequate to squeeze out the absolute maximum performance possible with this model architecture.\n",
    "\n",
    "20. **Critique the interpretability analysis performed (predicting probability for single words). While insightful, what potential inaccuracies or simplifications does this method introduce compared to how words contribute within a full review?**\n",
    "    *   Suggested Answer: This method is a simplification because it treats each word in isolation, ignoring the context provided by surrounding words. In reality, word meaning and sentiment contribution can be context-dependent. For example:\n",
    "        *   **Negation:** \"not good\" has the opposite sentiment of \"good.\"\n",
    "        *   **Intensifiers/Mitigators:** \"very bad\" vs. \"a bit bad.\"\n",
    "        *   **Sarcasm:** Context can completely flip the apparent sentiment of words.\n",
    "        *   **Phrases:** Multi-word expressions can have specific meanings (e.g., \"kick the bucket\").\n",
    "    The analysis provides a useful glimpse into which words the model *generally* associates with labels but doesn't reflect how these words interact within the structure of actual reviews."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "428408ac",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_course",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
