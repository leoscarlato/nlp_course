{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e7144cb0",
   "metadata": {},
   "source": [
    "# Funções importantes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a250f1a",
   "metadata": {},
   "source": [
    "`model.classes_` \n",
    "* Retorna as classes do modelo\n",
    "* Usado para saber qual é a classe 0, 1, ..., e entender a ordem das probabilidades retornadas pelo `predict_proba`\n",
    "``` python\n",
    "print(model.classes_)\n",
    "# Ex: ['comedy', 'drama']\n",
    "```\n",
    "-----------------------\n",
    "`model.coef_`\n",
    "* Retorna uma matriz com os pesos aprendidos pelo modelo (um vetor por classe, caso multiclasse)\n",
    "* Usado para saber quais palavras contribuem positivamente ou negativamente para cada classe\n",
    "``` python\n",
    "model.named_steps['clf'].coef_[0][idx]  # Peso da palavra no índice `idx`\n",
    "```\n",
    "Para saber as n palavras mais relevantes para cada classe, podemos usar o `argsort`:\n",
    "``` python\n",
    "# Ex: 10 palavras mais relevantes para a classe 0 (comédia)\n",
    "model.named_steps['clf'].coef_[0].argsort()[-10:][::-1]\n",
    "# Ex: 10 palavras mais relevantes para a classe 1 (drama)\n",
    "model.named_steps['clf'].coef_[1].argsort()[-10:][::-1]\n",
    "\n",
    "# Outro jeito de fazer isso é:\n",
    "\n",
    "vectorizer = pipe.named_steps['tfidf']\n",
    "clf = pipe.named_steps['clf']\n",
    "\n",
    "features = vectorizer.get_feature_names_out()\n",
    "coefs = clf.coef_[0]\n",
    "\n",
    "indices = np.argsort(coefs)[::-1][:10]\n",
    "print(\"Top 10 features:\")\n",
    "for i in indices:\n",
    "    print(f\"{features[i]}: {coefs[i]}\")\n",
    "\n",
    "# Para um problema multiclasse, podemos fazer o mesmo para cada classe:\n",
    "vectorizer = pipeline.named_steps['tfidf']\n",
    "clf = pipeline.named_steps['clf']\n",
    "\n",
    "features = vectorizer.get_feature_names_out()\n",
    "classes = clf.classes_\n",
    "coefs = clf.coef_  # Agora é (n_classes, n_features)\n",
    "\n",
    "# Exibindo as 10 palavras mais relevantes para cada classe\n",
    "for class_idx, class_label in enumerate(classes):\n",
    "    print(f\"\\nTop 10 palavras para a classe '{class_label}':\")\n",
    "    top_indices = np.argsort(coefs[class_idx])[::-1][:10]  # Top 10 maiores\n",
    "    for i in top_indices:\n",
    "        print(f\"{features[i]}: {coefs[class_idx][i]}\")\n",
    "```\n",
    "-----------------------\n",
    "\n",
    "`model.predict_proba([texto])`\n",
    "* Retorna um vetor contendo as probabilidades de cada classe para o texto passado como parâmetro\n",
    "* Usado para entender a confiança do modelo em relação a cada classe\n",
    "``` python\n",
    "model.predict_proba([texto])\n",
    "# Ex: [0.1, 0.9] -> 10% de chance de ser comédia, 90% de chance de ser drama\n",
    "```\n",
    "-----------------------\n",
    "\n",
    "`model.predict([texto])`\n",
    "* Retorna a classe prevista para o texto passado como parâmetro\n",
    "* Usado para fazer previsões em novos dados\n",
    "``` python\n",
    "model.predict([texto])\n",
    "# Ex: 'drama'\n",
    "```\n",
    "\n",
    "-----------------------\n",
    "`model.decision_function([texto])`\n",
    "* Retorna um vetor com os valores de decisão para cada classe (não normalizados)\n",
    "* Usado para entender a distância do texto em relação à fronteira de decisão entre as classes\n",
    "``` python\n",
    "model.decision_function([texto])\n",
    "# Ex: [0.5, -0.5] -> 0.5 para a classe 0 (comédia), -0.5 para a classe 1 (drama)\n",
    "```\n",
    "-----------------------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cd78a9f",
   "metadata": {},
   "source": [
    "Função | O que faz\n",
    "-----------------------|-----------------------\n",
    ".classes_ | Mostra os rótulos das classes\n",
    ".predict() | Retorna a classe prevista\n",
    ".predict_proba() | Retorna probabilidade de cada classe\n",
    ".decision_function() | Retorna logits (pré-sigmoide ou pré-softmax)\n",
    ".coef_ | Pesos das features (palavras)\n",
    ".intercept_ | Bias da função logística\n",
    ".vocabulary_ | Índices das palavras no vetor TF-IDF\n",
    ".get_feature_names_out() | Lista de palavras no vocabulário\n",
    "classification_report() | Avalia desempenho por classe\n",
    "softmax(z) | Transforma logits em probabilidades (multiclasse)\n",
    "1 / (1 + np.exp(-z)) | Transforma logit em probabilidade (binário)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97b877d0",
   "metadata": {},
   "source": [
    "| Situação | Função usada | decision_function retorna | predict_proba retorna|\n",
    "|----------------|----------------|---------------------|---------------------|\n",
    "| Binária | Sigmoide | 1 valor | [P(classe 0), P(classe 1)]\n",
    "| Multiclasse | Softmax | vetor (n_classes) | [P(classe 0), P(classe 1), ...]"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
